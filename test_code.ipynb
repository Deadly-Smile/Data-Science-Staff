{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Deadly-Smile/Data-Science-Staff/blob/main/test_code.ipynb",
      "authorship_tag": "ABX9TyPMKML907AdKPPyJWbJCJl1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deadly-Smile/Data-Science-Staff/blob/main/test_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#%%\n",
        "def smash_and_reconstruct(image, patch_size=32):\n",
        "    \"\"\"\n",
        "    Splits the image into patches, separates rich and poor texture regions,\n",
        "    and reconstructs two images: one for rich and one for poor textures.\n",
        "\n",
        "    Args:\n",
        "        image (numpy.ndarray): Input image of shape (H, W, 3) in RGB format.\n",
        "        patch_size (int): Size of each patch (default: 32).\n",
        "\n",
        "    Returns:\n",
        "        rich_texture (numpy.ndarray): Reconstructed image with rich texture patches.\n",
        "        poor_texture (numpy.ndarray): Reconstructed image with poor texture patches.\n",
        "    \"\"\"\n",
        "    height, width, channels = image.shape\n",
        "    assert channels == 3, \"Input image must have 3 channels (RGB).\"\n",
        "\n",
        "    # Pad image to be divisible by patch_size\n",
        "    pad_height = (patch_size - height % patch_size) % patch_size\n",
        "    pad_width = (patch_size - width % patch_size) % patch_size\n",
        "    image = np.pad(image, ((0, pad_height), (0, pad_width), (0, 0)), mode='reflect')\n",
        "\n",
        "    # Split into patches\n",
        "    patches = [\n",
        "        image[i:i+patch_size, j:j+patch_size]\n",
        "        for i in range(0, image.shape[0], patch_size)\n",
        "        for j in range(0, image.shape[1], patch_size)\n",
        "    ]\n",
        "\n",
        "    # Placeholder for texture analysis\n",
        "    rich_texture_patches = []\n",
        "    poor_texture_patches = []\n",
        "\n",
        "    for patch in patches:\n",
        "        # Calculate a \"texture richness\" score (variance of Laplacian)\n",
        "        gray_patch = cv2.cvtColor(patch, cv2.COLOR_RGB2GRAY)\n",
        "        texture_score = cv2.Laplacian(gray_patch, cv2.CV_64F).var()\n",
        "\n",
        "        # Arbitrary threshold: consider patches with high variance as \"rich textures\"\n",
        "        if texture_score > 50:  # Adjust threshold based on experimentation\n",
        "            rich_texture_patches.append(patch)\n",
        "            poor_texture_patches.append(np.zeros_like(patch))  # Placeholder\n",
        "        else:\n",
        "            poor_texture_patches.append(patch)\n",
        "            rich_texture_patches.append(np.zeros_like(patch))  # Placeholder\n",
        "\n",
        "    # Reconstruct images\n",
        "    rich_texture = reconstruct_image(rich_texture_patches, image.shape[:2], patch_size)\n",
        "    poor_texture = reconstruct_image(poor_texture_patches, image.shape[:2], patch_size)\n",
        "\n",
        "    return rich_texture, poor_texture\n",
        "\n",
        "def reconstruct_image(patches, image_shape, patch_size):\n",
        "    \"\"\"\n",
        "    Reconstructs an image from patches.\n",
        "\n",
        "    Args:\n",
        "        patches (list of numpy.ndarray): List of patches.\n",
        "        image_shape (tuple): Shape of the original image (H, W).\n",
        "        patch_size (int): Size of each patch.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Reconstructed image.\n",
        "    \"\"\"\n",
        "    reconstructed = np.zeros((image_shape[0], image_shape[1], 3), dtype=np.uint8)\n",
        "    idx = 0\n",
        "    for i in range(0, image_shape[0], patch_size):\n",
        "        for j in range(0, image_shape[1], patch_size):\n",
        "            reconstructed[i:i+patch_size, j:j+patch_size] = patches[idx]\n",
        "            idx += 1\n",
        "    return reconstructed\n",
        "\n",
        "#%%\n",
        "# class TextureDataset(Dataset):\n",
        "#     def __init__(self, root_dir, transform=None, patch_size=32, fraction=1.0):\n",
        "#         self.root_dir = root_dir\n",
        "#         self.transform = transform\n",
        "#         self.patch_size = patch_size\n",
        "#         self.data = []\n",
        "#         self.labels = []\n",
        "#\n",
        "#         # Load dataset\n",
        "#         for label, sub_dir in enumerate(['0_real', '1_fake']):\n",
        "#             folder = os.path.join(root_dir, sub_dir)\n",
        "#             files = os.listdir(folder)\n",
        "#             # Use only a fraction of the dataset\n",
        "#             sampled_files = files[:int(len(files) * fraction)]\n",
        "#             for file in sampled_files:\n",
        "#                 filepath = os.path.join(folder, file)\n",
        "#                 self.data.append(filepath)\n",
        "#                 self.labels.append(label)\n",
        "#\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "#\n",
        "#     def __getitem__(self, idx):\n",
        "#         filepath = self.data[idx]\n",
        "#         label = self.labels[idx]\n",
        "#\n",
        "#         # Load and process image\n",
        "#         image = cv2.imread(filepath)\n",
        "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#\n",
        "#         # Smash and Reconstruct\n",
        "#         rich_texture, poor_texture = smash_and_reconstruct(image, self.patch_size)\n",
        "#\n",
        "#         if self.transform:\n",
        "#             rich_texture = self.transform(rich_texture)\n",
        "#             poor_texture = self.transform(poor_texture)\n",
        "#\n",
        "#         # Concatenate rich and poor textures along the batch dimension\n",
        "#         # Each sample will now have shape [6, height, width]\n",
        "#         combined_textures = torch.cat([rich_texture, poor_texture], dim=0)\n",
        "#\n",
        "#         return combined_textures, label\n",
        "\n",
        "class TextureDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, patch_size=32, fraction=1.0, save_dir=None, save_preprocessed=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.patch_size = patch_size\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.save_dir = save_dir\n",
        "        self.save_preprocessed = save_preprocessed\n",
        "\n",
        "        # Load dataset\n",
        "        for label, sub_dir in enumerate(['0_real', '1_fake']):\n",
        "            folder = os.path.join(root_dir, sub_dir)\n",
        "            files = os.listdir(folder)\n",
        "            sampled_files = files[:int(len(files) * fraction)]\n",
        "            for file in sampled_files:\n",
        "                filepath = os.path.join(folder, file)\n",
        "                self.data.append(filepath)\n",
        "                self.labels.append(label)\n",
        "\n",
        "        if self.save_preprocessed and self.save_dir:\n",
        "            os.makedirs(self.save_dir, exist_ok=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Check if preprocessed data exists\n",
        "        if self.save_dir:\n",
        "            save_path = os.path.join(self.save_dir, f\"{idx}.pt\")\n",
        "            if os.path.exists(save_path):\n",
        "                data = torch.load(save_path)\n",
        "                return data[\"textures\"], data[\"label\"]\n",
        "\n",
        "        # Load and process image\n",
        "        image = cv2.imread(filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Smash and Reconstruct\n",
        "        rich_texture, poor_texture = smash_and_reconstruct(image, self.patch_size)\n",
        "\n",
        "        if self.transform:\n",
        "            rich_texture = self.transform(rich_texture)\n",
        "            poor_texture = self.transform(poor_texture)\n",
        "\n",
        "        # Concatenate textures\n",
        "        combined_textures = torch.cat([rich_texture, poor_texture], dim=0)\n",
        "\n",
        "        if self.save_preprocessed and self.save_dir:\n",
        "            # Save preprocessed data\n",
        "            torch.save({\"textures\": combined_textures, \"label\": label}, save_path)\n",
        "\n",
        "        return combined_textures, label\n",
        "\n",
        "#%%\n",
        "from torchvision.models import ResNet50_Weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class TextureResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextureResNet, self).__init__()\n",
        "        # Load pretrained ResNet-50\n",
        "        self.resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "\n",
        "        # Update the first convolution layer to handle 6 input channels\n",
        "        self.resnet.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        # Replace the final fully connected layer for binary classification\n",
        "        num_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "#%%\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=5):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for textures, labels in train_loader:\n",
        "            textures, labels = textures.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(textures)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        validate_model(model, val_loader, device)\n",
        "\n",
        "def validate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for textures, labels in val_loader:\n",
        "            textures, labels = textures.to(device), labels.to(device)\n",
        "            outputs = model(textures)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "#%%\n",
        "# Parameters\n",
        "root_dir = \"/content/drive/MyDrive/airplane\"\n",
        "batch_size = 16\n",
        "num_epochs = 25\n",
        "learning_rate = 0.0001  # Lower value for fine-tuning ResNet\n",
        "fraction = 1  # Use 30% of the dataset\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the image horizontally\n",
        "    transforms.RandomRotation(degrees=15),  # Randomly rotate the image by ±15 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
        "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load dataset (using a fraction)\n",
        "dataset = TextureDataset(root_dir, transform=transform, fraction=fraction, save_dir=\"airplane_processed\")\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#%%\n",
        "# Model, Loss, Optimizer\n",
        "model = TextureResNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Explicit learning rate\n",
        "\n",
        "# Train and Validate\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
        "# model.summary()\n",
        "torch.save(model, \"texture-based_1.pth\")\n",
        "torch.save(model.state_dict(), \"texture-based_2.pth\")\n"
      ],
      "metadata": {
        "id": "3of6yA8NrA_j",
        "outputId": "528eaf90-25dc-4b03-f734-8681dded4b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 113MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_model_on_dataset(model_path, root_dir, device, patch_size=32):\n",
        "    # Load model\n",
        "    model = TextureResNet()\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    # Transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Iterate through subdirectories (0_real and 1_fake)\n",
        "    for label, sub_dir in enumerate(['0_real', '1_fake']):\n",
        "        sub_dir_path = os.path.join(root_dir, sub_dir)\n",
        "        if not os.path.exists(sub_dir_path):\n",
        "            print(f\"Directory {sub_dir_path} does not exist. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        for image_name in os.listdir(sub_dir_path):\n",
        "            image_path = os.path.join(sub_dir_path, image_name)\n",
        "            if not os.path.isfile(image_path):\n",
        "                continue  # Skip non-file entries\n",
        "\n",
        "            # Load and process image\n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Smash and Reconstruct\n",
        "            rich_texture, poor_texture = smash_and_reconstruct(image, patch_size)\n",
        "            rich_texture = transform(rich_texture)\n",
        "            poor_texture = transform(poor_texture)\n",
        "\n",
        "            # Concatenate textures\n",
        "            combined_textures = torch.cat([rich_texture, poor_texture], dim=0).unsqueeze(0).to(device)\n",
        "\n",
        "            # Prediction\n",
        "            with torch.no_grad():\n",
        "                output = model(combined_textures)\n",
        "                _, prediction = torch.max(output, 1)\n",
        "\n",
        "            all_preds.append(prediction.item())\n",
        "            all_labels.append(label)\n",
        "\n",
        "    # Calculate and print accuracy\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Accuracy on the dataset: {accuracy:.4f}\")\n",
        "\n",
        "# Example Usage\n",
        "root_dir = \"/content/drive/MyDrive/airplane\"  # Replace with your test dataset root\n",
        "# model_path = \"texture-based_1.pth\"\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# evaluate_model_on_dataset(model_path, root_dir, device)\n",
        "model_path = \"texture-based_1.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "evaluate_model_on_dataset(model_path, root_dir, device)"
      ],
      "metadata": {
        "id": "6e1WzuvSrjQg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}